{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MBTIPredict.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cw59eCfw0-0"
      },
      "source": [
        "# Table of Contents\n",
        "- Setup and Imports\n",
        "- Model Features\n",
        "- Utility Functions\n",
        "- Data Loading\n",
        "- Stratified Train and Test Split\n",
        "- Determining the Distinguishing Words for each Personality Type\n",
        "- Processing the Raw Data\n",
        "- Fitting the Classifier\n",
        "- Test Accuracy and Error Analysis\n",
        "- Complete Workflow Execution\n",
        "\n",
        "Data downloaded from: https://www.kaggle.com/datasnaek/mbti-type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWfMVmRlxG0e"
      },
      "source": [
        "### Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoCiUw_frmpu"
      },
      "source": [
        "!pip install -U textblob\n",
        "!python -m textblob.download_corpora"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj9wk66WUk4A"
      },
      "source": [
        "import pickle\n",
        "from collections import Counter\n",
        "\n",
        "import functools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "from textblob import TextBlob\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit, cross_val_predict, cross_val_score\n",
        "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukqQQRXlxz58"
      },
      "source": [
        "### Model Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZdGkr1S7L--"
      },
      "source": [
        "# UF = Unimportant Feature\n",
        "\n",
        "POLARITY = 'polarity'\n",
        "SUBJECTIVITY = 'subjectivity'\n",
        "# AVG_SENTENCE_WORDS = 'avg_st_wds'  # UF\n",
        "# STD_SENTENCE_WORDS = 'std_st_wds'  # UF\n",
        "# AVG_SENTENCE_LENGTH = 'avg_st_len'  # UF\n",
        "# STD_SENTENCE_LENGTH = 'std_st_len'  # UF\n",
        "AVG_DESCRIPTOR_LENGTH = 'avg_wd_len'\n",
        "STD_DESCRIPTOR_LENGTH = 'std_wd_len'\n",
        "\n",
        "FEATURE_WORDS = [\n",
        "    'always',\n",
        "    # 'any',  # UF\n",
        "    'does',\n",
        "    'enfj',\n",
        "    'enfp',\n",
        "    'entj',\n",
        "    'entp',\n",
        "    # 'esfj',  # UF\n",
        "    # 'esfjs',  # UF\n",
        "    # 'esfp',  # UF\n",
        "    # 'estj',  # UF\n",
        "    # 'estp',  # UF\n",
        "    # 'even',  # UF\n",
        "    'feel',\n",
        "    # 'go',  # UF\n",
        "    'her',\n",
        "    'him',\n",
        "    # 'http',  # UF\n",
        "    # 'https',  # UF\n",
        "    'infj',\n",
        "    'infp',\n",
        "    'intj',\n",
        "    'intp',\n",
        "    'isfj',\n",
        "    'isfp',\n",
        "    'istj',\n",
        "    'istp',\n",
        "    # 'life',  # UF\n",
        "    # 'll',  # UF\n",
        "    'lot',\n",
        "    'love',\n",
        "    # 'make',  # UF\n",
        "    # 'myself',  # UF\n",
        "    # 'need',  # UF\n",
        "    # 'never',  # UF\n",
        "    # 'someone',  # UF\n",
        "    # 'sure',  # UF\n",
        "    # 'than',  # UF\n",
        "    'their',\n",
        "    # 'though',  # UF\n",
        "    'type',\n",
        "    # 'u',  # UF\n",
        "    'we',\n",
        "    'why',\n",
        "]\n",
        "PUNC_TOKENS = {\n",
        "    ',': 'punc_comma',\n",
        "    '.': 'punc_period',\n",
        "    # ';': 'punc_semicolon',  # UF\n",
        "    '(': 'punc_lparen',\n",
        "    ')': 'punc_rparen',\n",
        "    '?': 'punc_question',\n",
        "    '!': 'punc_exclam',\n",
        "    ':': 'punc_colon',\n",
        "    # '^': 'punc_hat',  # UF\n",
        "    # '*': 'punc_star',  # UF\n",
        "    # '%': 'punc_percent',  # UF\n",
        "    # '[': 'punc_lbrac',  # UF\n",
        "    # ']': 'punc_rbrac',  # UF\n",
        "    # '/': 'punc_fslash'  # UF\n",
        "}\n",
        "EXT_POLARITIES = 'ext_pol'\n",
        "EXT_SUBJECTIVITIES = 'ext_subj'\n",
        "# CLASS_IRONY = 'class_irony'  # UF\n",
        "CLASS_MOOD = 'class_mood'\n",
        "# CLASS_PROFANITY = 'class_prof'  # UF"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQBAff8S4kjE"
      },
      "source": [
        "BASE_FILE_PATH = \"drive/MyDrive/google_colab_data/mbti_class\"  # Replace with path to your folder\n",
        "RAW_DATA_PATH = f\"{BASE_FILE_PATH}/mbti_1.csv\"\n",
        "MBTI_TYPES = ['ENFJ', 'ENFP', 'ENTJ', 'ENTP', 'ESFJ', 'ESFP', 'ESTJ', 'ESTP', 'INFJ', 'INFP', 'INTJ', 'INTP', 'ISFJ', 'ISFP', 'ISTJ', 'ISTP']\n",
        "SAVED_COLS = [POLARITY, SUBJECTIVITY, AVG_DESCRIPTOR_LENGTH, STD_DESCRIPTOR_LENGTH, 'word_count', 'punc_count', 'word_assessments']\n",
        "DROP_COLS = [\n",
        "    'class_irony', 'class_prof', 'freq_any', 'freq_esfj', 'freq_esfjs', 'freq_esfp', 'freq_estj', 'freq_estp',\n",
        "    'freq_even', 'freq_go', 'freq_http', 'freq_https', 'freq_life', 'freq_ll', 'freq_make', 'freq_myself',\n",
        "    'freq_need', 'freq_never', 'freq_punc_fslash', 'freq_punc_hat', 'freq_punc_lbrac', 'freq_punc_percent',\n",
        "    'freq_punc_rbrac', 'freq_punc_semicolon', 'freq_punc_star', 'freq_someone', 'freq_sure', 'freq_than',\n",
        "    'freq_though', 'freq_u'\n",
        "]\n",
        "DESCRIPTOR_TYPES = {'JJ', 'JJR', 'JJS', 'NN', 'NNS', 'NNP', 'NNPS', 'PDT', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'}\n",
        "LABEL_COL = 'type'\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "RAW_POST_DELIMITER = '|||'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6W5ZC2wyKnv"
      },
      "source": [
        "### Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3s4suu6J5GW"
      },
      "source": [
        "def time_function(func):\n",
        "    @functools.wraps(func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = time()\n",
        "        res = func(*args, **kwargs)\n",
        "        print(f'[{round((time() - start), 5)} sec]', func.__name__)\n",
        "        return res\n",
        "    return wrapper"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak61Tk7vyRT9"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_0cj3LUWNOr"
      },
      "source": [
        "@time_function\n",
        "def load_raw_mbti_data(data_path: str):\n",
        "    with open(data_path, 'r') as f:\n",
        "        mbti_data = pd.read_csv(f)\n",
        "    \n",
        "    for _, row in mbti_data.iterrows():\n",
        "        row[LABEL_COL] = row[LABEL_COL].replace(RAW_POST_DELIMITER, '\\n')\n",
        "    \n",
        "    return mbti_data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ostcCDNrvXBR"
      },
      "source": [
        "@time_function\n",
        "def load_preprocessed_mbti_data(data_path, row_count=None):\n",
        "    if row_count:\n",
        "        mbti_data = pd.DataFrame(index=range(row_count))\n",
        "    else:\n",
        "        with open(data_path, 'r') as f:\n",
        "            mbti_data = pd.DataFrame(index=range(sum(1 for row in f) - 1))\n",
        "\n",
        "    for col in SAVED_COLS:\n",
        "        with open(f'{BASE_FILE_PATH}/full_posts_nlp_{col}.pkl', 'rb') as f:\n",
        "            mbti_data = mbti_data.join(pickle.load(f))\n",
        "    with open(f'{BASE_FILE_PATH}/full_posts_types.pkl', 'rb') as f:\n",
        "        mbti_data = mbti_data.join(pickle.load(f))\n",
        "\n",
        "    return mbti_data"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0yupP3eym0P"
      },
      "source": [
        "### Determining the Distinguishing Words for each Personality Type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnQSlXOiy2F9"
      },
      "source": [
        "WORD_COUNT_FILE_NAME_SUFFIX = 'word_freq'\n",
        "\n",
        "@time_function\n",
        "def compute_mbti_word_counts(mbti_data, max_most_common=100):\n",
        "    for mbti_type in MBTI_TYPES:\n",
        "        c = Counter()\n",
        "\n",
        "        for _, row in tqdm(mbti_data[mbti_data.type == mbti_type].iterrows(), mininterval=5):\n",
        "            text_analysis = TextBlob(row[LABEL_COL])\n",
        "            c += Counter(text_analysis.word_counts)\n",
        "\n",
        "        print(f'Saving {mbti_type} top {max_most_common} word counts...')\n",
        "        with open(f'{BASE_PATH}/{mbti_type}_{WORD_COUNT_FILE_NAME_SUFFIX}.pkl', 'wb') as f:\n",
        "            pickle.dump(c.most_common(max_most_common), f)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmN9oL2GvKKX"
      },
      "source": [
        "@time_function\n",
        "def compute_most_distinguishing_words(label_value_counts, max_most_common=10, score_threshold=8):\n",
        "    mbti_word_counts_catalogue = {}\n",
        "\n",
        "    for mbti_type in MBTI_TYPES:\n",
        "        with open(f'{BASE_PATH}/{mbti_type}_{WORD_COUNT_FILE_NAME_SUFFIX}.pkl', 'rb') as f:\n",
        "            type_word_counts = pickle.load(f)\n",
        "            words, freqs = list(map(list, zip(*type_word_counts)))\n",
        "            mbti_word_counts_catalogue[mbti_type] = dict(zip(words, np.array(freqs) / label_value_counts[mbti_type]))\n",
        "    \n",
        "    feature_words = set()\n",
        "    for mbti_type in MBTI_TYPES:\n",
        "        c = Counter()\n",
        "\n",
        "        for other_mbti_type in set(MBTI_TYPES) - {mbti_type}:\n",
        "            for word, freq in mbti_word_counts_catalogue[mbti_type].items():\n",
        "                c[word] += abs((mbti_word_counts_catalogue[other_mbti_type].get(word, 0) - freq) / freq)\n",
        "        \n",
        "        distinguishing_words = [\n",
        "            word for word, score in c.most_common(max_most_common) if score >= score_threshold and word.isalpha()\n",
        "        ]\n",
        "        feature_words.update(distinguishing_words)\n",
        "    \n",
        "    return feature_words"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxgMetmbyZd7"
      },
      "source": [
        "### Stratified Train and Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8tqOF-fWTx6"
      },
      "source": [
        "@time_function\n",
        "def stratify_split_mbti_data(mbti_data, test_size=0.25, random_state=RANDOM_STATE):\n",
        "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
        "    for train_idx, test_idx in splitter.split(mbti_data, mbti_data[LABEL_COL]):\n",
        "        strat_train_data = mbti_data.iloc[train_idx, :].reset_index(drop=True)\n",
        "        strat_test_data = mbti_data.iloc[test_idx, :].reset_index(drop=True)\n",
        "    return strat_train_data, strat_test_data"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Adl56MCty6KF"
      },
      "source": [
        "### Processing the Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnKMBAX1vk6Z"
      },
      "source": [
        "class PostProcessor(BaseException, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def get_sentiment_assessment_stats(self, assessments):\n",
        "        try:\n",
        "            _, polarities, subjectivities, word_types = list(map(list, zip(*assessments)))\n",
        "        except Exception:\n",
        "            polarities, subjectivities, word_types = [], [], []\n",
        "        return {\n",
        "            EXT_POLARITIES: sum(1 for pol in polarities if abs(pol) >= 0.3),\n",
        "            EXT_SUBJECTIVITIES: sum(1 for subj in subjectivities if abs(subj) >= 0.3),\n",
        "            CLASS_MOOD: sum(1 for word_type in word_types if word_type == 'mood')\n",
        "        }\n",
        "\n",
        "    def get_punctuation_token_stats(self, tokens):\n",
        "        return {f'freq_{label}': tokens.count(token) for token, label in PUNC_TOKENS.items()}\n",
        "\n",
        "    def get_word_count_stats(self, word_counts):\n",
        "        return {f'freq_{feature_word}': word_counts.get(feature_word, 0) for feature_word in FEATURE_WORDS}\n",
        "\n",
        "    def get_descriptor_stats(self, tags):\n",
        "        descriptors = [\n",
        "            len(word) for word, POS in tags\n",
        "            if POS in DESCRIPTOR_TYPES and not word.startswith('//') and not word.startswith('v=') and word.isalpha()\n",
        "        ]\n",
        "        return {\n",
        "            AVG_DESCRIPTOR_LENGTH: np.mean(descriptors),\n",
        "            STD_DESCRIPTOR_LENGTH: np.std(descriptors)\n",
        "        }\n",
        "\n",
        "    def get_text_features(self, post):\n",
        "        post_analysis = TextBlob(post)\n",
        "\n",
        "        new_entry = {\n",
        "            POLARITY: post_analysis.sentiment.polarity,\n",
        "            SUBJECTIVITY: post_analysis.sentiment.subjectivity,\n",
        "        }\n",
        "        new_entry.update(self.get_descriptor_stats(post_analysis.tags))\n",
        "        new_entry.update(self.get_sentiment_assessment_stats(post_analysis.sentiment_assessments.assessments))\n",
        "        new_entry.update(self.get_punctuation_token_stats(post_analysis.tokens))\n",
        "        new_entry.update(self.get_word_count_stats(post_analysis.word_counts))\n",
        "        \n",
        "        return new_entry\n",
        "\n",
        "    @time_function\n",
        "    def transform(self, X):\n",
        "        transformed_X = [self.get_text_features(row['posts']) for idx, row in tqdm(X.iterrows(), mininterval=10)]\n",
        "        return pd.DataFrame(transformed_X)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhMf1oFeroTg"
      },
      "source": [
        "@time_function\n",
        "def prepare_data(data, preprocessed=False):\n",
        "    standard_scaler = StandardScaler()\n",
        "    ordinal_encoder = OrdinalEncoder()\n",
        "\n",
        "    if preprocessed:\n",
        "        data_num_prepared = standard_scaler.fit_transform(data.drop([LABEL_COL] + DROP_COLS, axis=1, errors='ignore'))\n",
        "    else:\n",
        "        data_num_prepared = PostProcessor().fit_transform(data)\n",
        "        data_num_prepared = standard_scaler.fit_transform(data_num_prepared.drop([LABEL_COL] + DROP_COLS, axis=1, errors='ignore'))\n",
        "    data_cat_prepared = ordinal_encoder.fit_transform(data[[LABEL_COL]].values).reshape(-1)\n",
        "\n",
        "    return data_num_prepared, data_cat_prepared, ordinal_encoder"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8mJUNxPzGld"
      },
      "source": [
        "### Fitting the Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5kgPCOXxRLq"
      },
      "source": [
        "@time_function\n",
        "def fit_classifier(train_data_features, train_data_labels):\n",
        "    clf = VotingClassifier(\n",
        "        estimators=[\n",
        "            ('svc', SVC(kernel='rbf', gamma='scale', C=0.25, probability=True)),\n",
        "            ('forest', RandomForestClassifier(criterion='gini', n_estimators=100, min_samples_leaf=1)),\n",
        "            ('logistic', LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", C=0.05, max_iter=5000)),\n",
        "        ],\n",
        "        voting='soft',\n",
        "        weights=[0.4, 0.4, 0.2]\n",
        "    )\n",
        "    clf.fit(train_data_features, train_data_labels)\n",
        "    return clf"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP5LChK5Q8oB"
      },
      "source": [
        "def grid_search_clf(clf_type, train_data_features, train_data_labels, param_grid, cross_valid=2):\n",
        "    if clf_type == 'svc':\n",
        "        clf = SVC(kernel='rbf', gamma='scale', probability=True)\n",
        "    elif clf_type == 'forest':\n",
        "        clf = RandomForestClassifier()\n",
        "    elif clf_type == 'logistic':\n",
        "        clf = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", max_iter=5000)\n",
        "\n",
        "    grid_search = GridSearchCV(clf, param_grid, cv=cross_valid, scoring='precision_macro', return_train_score=True, verbose=2)\n",
        "    grid_search.fit(train_data_features, train_data_labels)\n",
        "    return grid_search\n",
        "\n",
        "@time_function\n",
        "def get_best_clf_params(train_data_features, train_data_labels, svc=False, forest=False, logistic=False):\n",
        "    if svc:\n",
        "        svc_grid_search = grid_search_clf(\n",
        "            'svc',\n",
        "            train_data_features, train_data_labels,\n",
        "            param_grid=[{'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.25, 0.5, 1]}]\n",
        "        )\n",
        "        print(svc_grid_search.best_params_)\n",
        "    if forest:\n",
        "        forest_grid_search = grid_search_clf(\n",
        "            'forest',\n",
        "            train_data_features, train_data_labels,\n",
        "            param_grid=[{'n_estimators': [2, 5, 10, 25, 50, 100, 200], 'criterion': ['entropy', 'gini'], 'min_samples_leaf': [1, 2]}]\n",
        "        )\n",
        "        print(forest_grid_search.best_params_)\n",
        "    if logistic:\n",
        "        log_grid_search = grid_search_clf(\n",
        "            'logistic',\n",
        "            train_data_features, train_data_labels,\n",
        "            param_grid=[{'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.25, 0.5, 1]}]\n",
        "        )\n",
        "        print(log_grid_search.best_params_)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puwpF-T4zMPj"
      },
      "source": [
        "### Test Accuracy and Error Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zh1dYVFtjo15"
      },
      "source": [
        "@time_function\n",
        "def get_test_accuracy(clf, test_data_features, test_data_labels):\n",
        "    pred = clf.predict(test_data_features)\n",
        "    return accuracy_score(test_data_labels, pred)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62yZRrJHPwVe"
      },
      "source": [
        "@time_function\n",
        "def get_cross_valid_score(clf, train_data_features, train_data_labels, cross_val=3):\n",
        "    return cross_val_score(clf, train_data_features, train_data_labels, cv=cross_val, scoring=\"accuracy\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oGzF_nhQVqI"
      },
      "source": [
        "@time_function\n",
        "def show_conf_mat(clf, train_data_features, train_data_labels, cross_val=3, normalized=False):\n",
        "    cross_val_predictions = cross_val_predict(clf, train_data_features, train_data_labels, cv=cross_val)\n",
        "    conf_mx = confusion_matrix(train_data_labels, cross_val_predictions)\n",
        "\n",
        "    if normalized:\n",
        "        row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
        "        norm_conf_mx = conf_mx / row_sums\n",
        "        np.fill_diagonal(norm_conf_mx, 0)\n",
        "        plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
        "    else:\n",
        "        plt.matshow(conf_mx, cmap=plt.cm.gray)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP3seZA4iQxx"
      },
      "source": [
        "@time_function\n",
        "def get_ordered_feature_importances(clf, train_data, top_imp=50):\n",
        "    print(\n",
        "        *(\n",
        "            sorted(\n",
        "                list(zip(train_data.columns, clf.feature_importances_)),\n",
        "                key=lambda pair: pair[1],\n",
        "                reverse=True\n",
        "            )[:top_imp]\n",
        "         ),\n",
        "        sep='\\n'\n",
        "    )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daU5LdHOzQUo"
      },
      "source": [
        "### Complete Workflow Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhhELDmJgn4t"
      },
      "source": [
        "def execute_workflow(load_saved=False):\n",
        "    if load_saved:\n",
        "        mbti_data = load_preprocessed_mbti_data(RAW_DATA_PATH, row_count=8675)\n",
        "    else:\n",
        "        mbti_data = load_raw_mbti_data(RAW_DATA_PATH)\n",
        "    \n",
        "    strat_train_data, strat_test_data = stratify_split_mbti_data(mbti_data)\n",
        "    train_data_features, train_data_labels, train_ord_encoder = prepare_data(strat_train_data, preprocessed=load_saved)\n",
        "\n",
        "    clf = fit_classifier(train_data_features, train_data_labels)\n",
        "\n",
        "    test_data_features, test_data_labels, test_ord_encoder = prepare_data(strat_test_data, preprocessed=load_saved)\n",
        "    test_accuracy = get_test_accuracy(clf, test_data_features, test_data_labels)\n",
        "    print(f\"Accuracy: {round(test_accuracy, 5)}\")\n",
        "\n",
        "execute_workflow(load_saved=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}